import os
import json
import time
import re
import faiss
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

# =========================================================
# [ì „ì—­ ë³€ìˆ˜ ì„¤ì •]
# =========================================================
embedder = None
index = None
id_map = {}
scenarios = []
id_to_text_map = {}
client = None

# =========================================================
# 1. ì´ˆê¸°í™” í•¨ìˆ˜ (ë°ì´í„° ë¡œë“œ) - ê²½ë¡œ ë¬¸ì œ í•´ê²° ë²„ì „
# =========================================================
def initialize_data():
    global embedder, index, id_map, scenarios, id_to_text_map, client
    
    print("â³ ë°ì´í„° ë¡œë”© ë° ì´ˆê¸°í™” ì¤‘...")

    # [í•µì‹¬ ìˆ˜ì •] í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ íŒŒì¼(cpx_engine.py)ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ ì¡ìŠµë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•˜ë©´ ì„œë²„ì˜ í˜„ì¬ ì‘ì—… í´ë”ê°€ ì–´ë””ë“  ìƒê´€ì—†ì´ í•­ìƒ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))

    # 1. API í‚¤ ë¡œë“œ
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ .env íŒŒì¼ ë˜ëŠ” Secretsì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
        
    client = OpenAI(api_key=api_key)
    
    # 2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    try:
        embedder = SentenceTransformer('jhgan/ko-sroberta-multitask')
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    # 3. ë°ì´í„° íŒŒì¼ ë¡œë“œ
    try:
        # [ìˆ˜ì •] ì ˆëŒ€ ê²½ë¡œ ìƒì„±
        faiss_path = os.path.join(BASE_DIR, 'headache.faiss')
        meta_path = os.path.join(BASE_DIR, 'headache_meta.json')
        scenarios_path = os.path.join(BASE_DIR, 'headache_scenarios.json')
        master_path = os.path.join(BASE_DIR, 'headache_master.json')

        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        if os.path.exists(faiss_path):
            index = faiss.read_index(faiss_path)
        else:
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {faiss_path}")
            return False

        # ë©”íƒ€ ë°ì´í„° ë¡œë“œ
        if os.path.exists(meta_path):
            with open(meta_path, 'r', encoding='utf-8') as f:
                id_map = json.load(f)
        else:
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {meta_path}")
            return False

        # ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ë¡œë“œ
        if os.path.exists(scenarios_path):
            with open(scenarios_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                scenarios = data.get('scenarios', [])
        else:
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {scenarios_path}")
            return False
            
        # ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ (Re-rankingìš©)
        if os.path.exists(master_path):
            with open(master_path, 'r', encoding='utf-8') as f:
                master_data = json.load(f)
            # id_to_text_mapì´ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ê³  ì—…ë°ì´íŠ¸
            if 'id_to_text_map' not in globals():
                id_to_text_map = {} 
            for item in master_data.get('checklist', []):
                id_to_text_map[item['id']] = item['standard_text']
        else:
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {master_path} (ì§ˆë¬¸ ë§¤ì¹­ ì •í™•ë„ í•˜ë½ ê°€ëŠ¥)")
            
        print("âœ… ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return True

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

# =========================================================
# 2. GPT í˜¸ì¶œ í—¬í¼ (max_tokens íŒŒë¼ë¯¸í„° ì§€ì›)
# =========================================================
def generate_gpt(prompt, model="gpt-4o", max_tokens=300):
    if not client: return "API Client Error"
    
    max_retries = 3
    for i in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜í•™ ì‹œë®¬ë ˆì´ì…˜ì˜ í‘œì¤€í™” í™˜ì(SP) í˜¹ì€ ì±„ì ê´€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7, 
                max_tokens=max_tokens 
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if "RateLimit" in str(e):
                time.sleep(1)
            else:
                return f"Error: {e}"
    return "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"

# =========================================================
# 3. í™˜ì ì—”ì§„ (ëŒ€í™” ì²˜ë¦¬)
# =========================================================
def search_and_process(patient, user_text):
    # 1. í›„ë³´êµ° ì¶”ì¶œ (Top 10)
    vector = embedder.encode([user_text])
    faiss.normalize_L2(vector)
    similarities, indices = index.search(vector, 10) 
    
    candidates_list_str = ""
    for i in range(10):
        q_id = id_map[indices[0][i]]
        std_text = id_to_text_map.get(q_id, "ë‚´ìš© ë¯¸ìƒ")
        candidates_list_str += f"- {q_id}: {std_text}\n"

    # 2. GPT Re-ranking & Acting (í˜ë¥´ì†Œë‚˜ ì ìš©)
    profile = patient['profile']
    
    prompt = f"""
    [ì—­í• ] {profile['name']} ({profile['age']}ì„¸, {profile['job']}), ì˜í•™ ì§€ì‹ ì—†ìŒ.
    [ì§ˆë¬¸] "{user_text}"
    
    [1ë‹¨ê³„: ì˜ë„ ë§¤ì¹­]
    ì•„ë˜ í›„ë³´ ì¤‘ ì§ˆë¬¸ê³¼ ê°€ì¥ ì¼ì¹˜í•˜ëŠ” IDë¥¼ ê³ ë¥´ì„¸ìš”.
    {candidates_list_str}
    
    [2ë‹¨ê³„: ë‹µë³€ ìƒì„±]
    ì„ íƒí•œ IDì˜ [Fact]ë¥¼ ì°¾ì•„ í™˜ì ë§íˆ¬ë¡œ ì—°ê¸°í•˜ì„¸ìš”.
    [Fact Data]: {json.dumps(patient['fact_sheet'], ensure_ascii=False)}
    
    â˜… [ë§íˆ¬ ê°€ì´ë“œë¼ì¸]
    1. **ì˜í•™ ìš©ì–´ ê¸ˆì§€**: "ë°œì—´"->"ì—´ë‚˜ìš”", "ì˜¤í•œ"->"ì¶”ì›Œìš”"
    2. **êµ¬ì–´ì²´/ê°ì •**: "ì•„ë‹ˆìš”"->"ì•„ë‡¨, ì—†ì—ˆì–´ìš”.", ì•„í”ˆ ì†Œë¦¬(...ìœ¼ìœ¼..) í¬í•¨.
    3. **ë°ì´í„° ë¶€ì¬ ì‹œ**: "ì˜ ëª¨ë¥´ê² ì–´ìš”" ë˜ëŠ” "ê¸°ì–µ ì•ˆ ë‚˜ìš”". (ì§€ì–´ë‚´ê¸° ê¸ˆì§€)
    
    [ì¶œë ¥ í¬ë§·]
    ID || í™˜ìëŒ€ì‚¬
    """
    
    raw_response = generate_gpt(prompt, max_tokens=300)
    
    sel_id = "Unknown"
    reply = "ì£„ì†¡í•´ìš”, ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
    
    try:
        if raw_response and "||" in raw_response:
            parts = raw_response.split("||")
            sel_id = parts[0].strip()
            reply = parts[1].strip()
            # ID ì •ì œ
            sel_id = re.sub(r'^[0-9]+[\.\-\)\s]*', '', sel_id).replace("[", "").replace("]", "").strip()
        elif raw_response:
            reply = raw_response
    except: pass

    # 3. ê°•ì œ ë¶€ì • ë¡œì§ (ë°ì´í„° ì—†ì„ ë•Œ ê±°ì§“ë§ ë°©ì§€)
    real_fact = patient['fact_sheet'].get(sel_id)
    if not real_fact and sel_id != "Unknown" and sel_id != "Empathy":
        if any(k in sel_id for k in ['History', 'Experience', 'AssociatedSx']):
            reply = "ì•„ë‡¨, ê·¸ëŸ° ê±´ ë”±íˆ ì—†ì—ˆì–´ìš”."
        else:
            reply = "ê¸€ì„ìš”... ì •í™•íˆëŠ” ì˜ ê¸°ì–µì´ ì•ˆ ë‚˜ë„¤ìš”."
            
    return sel_id, reply

# =========================================================
# 4. ì±„ì  í•¨ìˆ˜ (í‰ê°€ ë¡œì§)
# =========================================================
def evaluate_assessment(patient, user_answers, chat_history):
    """
    Step 4: ì¢…í•© ì±„ì  
    (1) ë³‘ë ¥ì²­ì·¨ (Demographics, PE ì œì™¸)
    (2) í™˜ìêµìœ¡ (10ì )
    (3) PPI (18ì  í‘œ)
    (4) ì§„ë‹¨/ê³„íš
    """
    true_dx = patient['target_disease']
    true_plan = ", ".join(patient['diagnostic_plan'])
    
    # ---------------------------------------------------------
    # ğŸ› ï¸ [ì±„ì  ê¸°ì¤€ í•„í„°ë§]
    # - ê°’ì´ ë¹„ì–´ìˆëŠ” í•­ëª© ì œì™¸
    # - 'KQ_Demographics'ë¡œ ì‹œì‘í•˜ëŠ” í•­ëª© ì œì™¸
    # - 'PE'ë¡œ ì‹œì‘í•˜ëŠ” í•­ëª© ì œì™¸
    # ---------------------------------------------------------
    checklist_items = []
    for k, v in patient['fact_sheet'].items():
        if not v: continue # ê°’ ì—†ìŒ ì œì™¸
        if k.startswith('KQ_Demographics'): continue # ì¸ì ì‚¬í•­ ì œì™¸
        if k.startswith('PE'): continue # ì‹ ì²´ì§„ì°° ì œì™¸
        
        checklist_items.append(f"- {k} (ë‚´ìš©: {v})")

    checklist_str = "\n".join(checklist_items)

    # í•™ìƒ ë‹µì•ˆ í¬ë§·íŒ…
    student_dx_plan = ""
    for item in user_answers:
        dx = item['dx'] if item['dx'] else "(ì…ë ¥ ì•ˆ í•¨)"
        plan = item['plan'] if item['plan'] else "(ì…ë ¥ ì•ˆ í•¨)"
        student_dx_plan += f"- [{item['rank']}ìˆœìœ„] ì§„ë‹¨: {dx} | ê²€ì‚¬: {plan}\n"

    # ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…
    transcript = ""
    for msg in chat_history:
        role = "ì˜ì‚¬" if msg['role'] == "user" else "í™˜ì"
        transcript += f"{role}: {msg['content']}\n"

    # ë©”ê°€ í”„ë¡¬í”„íŠ¸ ì‘ì„±
    prompt = f"""
    ë‹¹ì‹ ì€ ì˜ì‚¬ êµ­ê°€ê³ ì‹œ ì‹¤ê¸°(CPX) ìˆ˜ì„ ì±„ì ê´€ì…ë‹ˆë‹¤.
    ì œê³µëœ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ 4ê°€ì§€ í•­ëª©ì„ ì±„ì í•˜ì—¬ ì„±ì í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    [ìƒí™© ì •ë³´]
    - ì •ë‹µ ì§„ë‹¨: {true_dx}
    - í•„ìˆ˜ ê²€ì‚¬: {true_plan}
    
    [ì±„ì  ëŒ€ìƒ í•„ìˆ˜ ë¬¸ì§„ í•­ëª© (Checklist)]
    {checklist_str}

    [ì§„ë£Œ ëŒ€í™” ê¸°ë¡]
    {transcript}

    [í•™ìƒ ë‹µì•ˆ]
    {student_dx_plan}

    ---
    [ì±„ì  ê¸°ì¤€ ë° ì¶œë ¥ ì–‘ì‹ (Markdown)]
    
    # ğŸ“Š CPX ì¢…í•© ì„±ì í‘œ

    ## 1. ë³‘ë ¥ ì²­ì·¨ (History Taking)
    * **ì±„ì  ë°©ì‹**: ìœ„ [ì±„ì  ëŒ€ìƒ í•„ìˆ˜ ë¬¸ì§„ í•­ëª©]ì— ìˆëŠ” ì •ë³´ë“¤ì„ ì˜ì‚¬ê°€ ì§ˆë¬¸ì„ í†µí•´ ì•Œì•„ëƒˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
    * **ì£¼ì˜**: ì§ˆë¬¸ì„ í•˜ì§€ ì•Šì•„ë„ í™˜ìê°€ ìŠ¤ìŠ¤ë¡œ ë§í•œ ì •ë³´ëŠ” íšë“í•œ ê²ƒìœ¼ë¡œ ì¸ì •í•©ë‹ˆë‹¤.
    * **ì¶œë ¥ í˜•ì‹**: 
      - ì²´í¬ë¦¬ìŠ¤íŠ¸ í‘œ (í•­ëª©ëª… | íšë“ì—¬ë¶€(O/X) | ë°°ì (1ì ))
      - **ì´ì **: (íšë“ì ìˆ˜) / (ì´ í•­ëª© ìˆ˜) ì 

    ## 2. í™˜ì êµìœ¡ (Patient Education)
    * **ì±„ì  ê¸°ì¤€**: ì§„ë£Œ í›„ë°˜ë¶€ì— í™˜ìì—ê²Œ í˜„ì¬ ìƒíƒœ(ì§„ë‹¨), ê²€ì‚¬ ê³„íš, ìƒí™œ ìŠµê´€ êµì • ë“±ì„ ì„¤ëª…í–ˆëŠ”ê°€?
    * **ì¶œë ¥ í˜•ì‹**:
      - êµìœ¡ ì—¬ë¶€: (ìˆìŒ/ì—†ìŒ)
      - ë‚´ìš© ì¶©ì‹¤ë„ í‰ê°€: (êµìœ¡ ë‚´ìš© ìš”ì•½ ë° í‰ê°€ 1ë¬¸ì¥)
      - **ì ìˆ˜**: (0~10ì ) / 10ì  ë§Œì 

    ## 3. ì˜ì‚¬-í™˜ì ê´€ê³„ (PPI)
    * **ì±„ì  ê¸°ì¤€**: ì•„ë˜ 6ê°œ í•­ëª© í‰ê°€ (3:ì•„ì£¼ìš°ìˆ˜, 2:ìš°ìˆ˜, 1:ë³´í†µ, 0:ë¯¸í¡)
    * **ì¶œë ¥ í˜•ì‹**: (ì•„ë˜ í‘œ ì‘ì„±)
    | í‰ê°€ í•­ëª© | ì ìˆ˜ (0~3) | í‰ê°€ ê·¼ê±° |
    |---|---|---|
    | 1. íš¨ìœ¨ì ì¸ ë³‘ë ¥ ì²­ì·¨ | | |
    | 2. ê²½ì²­ ë° ê³µê°ì  íƒœë„ | | |
    | 3. ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª… | | |
    | 4. í™˜ìì˜ ì˜ê²¬ ì¡´ì¤‘ | | |
    | 5. ë¹„ì–¸ì–´ì  ì†Œí†µ(íƒœë„) | | |
    | 6. ì‹ ë¢°ê° ë° ì „ë¬¸ì„± | | |
    * **PPI ì´ì **: (í•©ê³„) / 18ì 

    ## 4. ì§„ë‹¨ ë° ê³„íš (Assessment & Plan)
    * **ì§„ë‹¨ ì •í™•ë„**: (ì •ë‹µ ì§„ë‹¨ í¬í•¨ ì—¬ë¶€ O/X)
    * **ê²€ì‚¬ ì ì ˆì„±**: (í•„ìˆ˜ ê²€ì‚¬ í¬í•¨ ì—¬ë¶€ O/X)
    * **í”¼ë“œë°±**: (ì˜í•™ì  ì¡°ì–¸)

    ## ğŸ† ìµœì¢… ì´í‰
    > (í•™ìƒì—ê²Œ ì „í•˜ëŠ” ì¡°ì–¸)
    """
    
    # ê¸´ ë¦¬í¬íŠ¸ë¥¼ ìœ„í•´ í† í° ì œí•œ ëŠ˜ë¦¼

    return generate_gpt(prompt, max_tokens=3000)
